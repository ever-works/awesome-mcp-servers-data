name: Minima
description: A local RAG (Retrieval-Augmented Generation) solution with an MCP
  server, enabling on-premises use of Model Context Protocol for private data
  and AI workflows.
source_url: https://dev.to/dmayboroda/deployable-on-premises-rag-29oc
category: ai-integration-mcp-servers
tags:
  - mcp
  - rag
  - ai-integration
  - data-access
markdown: >
  # Minima


  **Category:** AI Integration, MCP Servers


  **Website:** [Minima on
  DEV.to](https://dev.to/dmayboroda/deployable-on-premises-rag)


  ---


  ## Description

  Minima is an open-source, containerized Retrieval-Augmented Generation (RAG)
  solution designed for on-premises deployment or integration with external
  large language models (LLMs) such as ChatGPT or Anthropic Claude. It enables
  secure, flexible, and private AI workflows for handling local data using the
  Model Context Protocol (MCP).


  ---


  ## Features

  - **Deployment Modes:**
    - **Isolated Installation:**
      - Fully on-premises operation with no external dependencies.
      - All neural networks (LLM, reranker, and embedding) run locally or in your own cloud.
      - Ensures data privacy and security.
    - **Custom GPT Integration:**
      - Query local documents via the ChatGPT app or web interface using custom GPTs.
      - Local or cloud-based indexer with ChatGPT as the LLM.
    - **Anthropic Claude Integration:**
      - Query local documents using the Claude app.
      - Local indexer with Anthropic Claude as the LLM.
  - **Security:** Data remains local for on-premises mode, prioritizing privacy.

  - **Flexibility:** Can be used fully locally or with popular external LLMs.

  - **Containerized:** Easy deployment and management.

  - **Open Source:** Source code available for customization and inspection.


  ---


  ## Pricing

  No pricing information provided; Minima is open-source.


  ---


  ## Tags

  mcp, rag, ai-integration, data-access
updated_at: 2025-05-14 00:46
