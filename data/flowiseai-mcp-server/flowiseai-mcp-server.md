# FlowiseAI MCP Server

Open‑source UI and visual tool to build and orchestrate LLM applications via the Model Context Protocol (MCP), powered by Pipedream Connect.

- **Name:** FlowiseAI MCP Server  
- **Category:** AI Integration – MCP Servers  
- **Website / Source:** https://mcp.pipedream.com/app/flowiseai  
- **MCP Server URL:** `https://mcp.pipedream.net/v2`  
- **Brand:** FlowiseAI

## Description
FlowiseAI MCP Server exposes FlowiseAI’s open‑source visual LLM app‑building capabilities through a standard MCP endpoint. It lets compatible chat or LLM clients connect to FlowiseAI workflows and tools using a single static MCP URL.

## Features
- **Static MCP Endpoint**  
  - Single, shared MCP server URL: `https://mcp.pipedream.net/v2`  
  - Same endpoint works across all supported MCP clients.

- **Client‑agnostic Integration**  
  - Can be added to any MCP‑compatible chat or LLM client.  
  - Configuration guidance available via the platform’s configuration docs.

- **Visual LLM App Building (via FlowiseAI)**  
  - Connects to FlowiseAI’s open‑source, node‑based visual editor for LLM applications.  
  - Suitable for building and orchestrating LLM workflows that can then be accessed through MCP.

- **Orchestration via Model Context Protocol**  
  - Exposes FlowiseAI tools and workflows as MCP resources/tools.  
  - Allows LLM clients to call FlowiseAI logic through a standardized protocol.

- **Hosted and Managed by Pipedream Connect**  
  - Server endpoint is provided and operated by Pipedream Connect.  
  - Centralized terms and privacy policies (via Pipedream).

## Integration
- Add the server by using the static URL `https://mcp.pipedream.net/v2` in your MCP‑compatible application.  
- Client‑specific setup steps are available from the linked configuration documentation on the source site.

## Pricing
- Not specified in the provided content.